{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8229357",
   "metadata": {},
   "source": [
    "# Observability\n",
    "\n",
    "이 워크샵에서는 Agent Framework에서 OpenTelemetry를 사용하여 AI 애플리케이션을 관찰하고 모니터링하는 방법을 학습합니다.\n",
    "\n",
    "## 목차\n",
    "1. [Observability란 무엇인가?](#observability란-무엇인가)\n",
    "2. [환경 설정](#환경-설정)\n",
    "3. [기본 Observability 설정](#기본-observability-설정)\n",
    "4. [ChatAgent Observability](#chatagent-observability)\n",
    "5. [Azure AI Agent Observability](#azure-ai-agent-observability)\n",
    "6. [Custom Span 생성](#custom-span-생성)\n",
    "7. [Workflow Observability](#workflow-observability)\n",
    "8. [Application Insights 연동](#application-insights-연동)\n",
    "\n",
    "## 학습 목표\n",
    "- OpenTelemetry와 Observability 개념 이해\n",
    "- Agent Framework의 자동 계측(instrumentation) 활용\n",
    "- Traces, Logs, Metrics 수집 및 분석\n",
    "- Azure Application Insights 연동\n",
    "- Aspire Dashboard를 통한 로컬 개발 모니터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0fe3df",
   "metadata": {},
   "source": [
    "## 1. Observability란 무엇인가?\n",
    "\n",
    "**Observability**는 시스템의 내부 상태를 외부 출력을 통해 이해할 수 있는 능력입니다.\n",
    "\n",
    "### OpenTelemetry 3대 요소\n",
    "\n",
    "1. **Traces (추적)** 🔍\n",
    "   - 요청이 시스템을 통과하는 전체 경로\n",
    "   - Span: 단일 작업 단위\n",
    "   - Agent 실행, 함수 호출, AI 모델 호출 등\n",
    "   - 분산 시스템의 성능 병목 지점 파악\n",
    "\n",
    "2. **Logs (로그)** 📝\n",
    "   - 특정 시점의 이벤트 기록\n",
    "   - 디버깅 및 문제 해결\n",
    "   - 컨텍스트 정보 포함\n",
    "   - 로그 레벨: DEBUG, INFO, WARNING, ERROR\n",
    "\n",
    "3. **Metrics (메트릭)** 📊\n",
    "   - 시간 경과에 따른 수치 데이터\n",
    "   - 토큰 사용량, 응답 시간, 에러율\n",
    "   - 성능 모니터링 및 알림\n",
    "   - 리소스 사용량 추적\n",
    "\n",
    "### Agent Framework Observability\n",
    "\n",
    "Agent Framework는 **OpenTelemetry Semantic Conventions for GenAI**를 따라 자동으로 telemetry를 생성합니다:\n",
    "\n",
    "- ✅ **Agent/Model 호출**: 모든 AI 모델 호출 자동 추적\n",
    "- ✅ **Tool 실행**: 함수 호출 및 실행 시간 기록\n",
    "- ✅ **토큰 소비**: 입력/출력 토큰 수 자동 집계\n",
    "- ✅ **에러 추적**: 예외 및 실패 자동 로깅\n",
    "- ✅ **워크플로우**: End-to-end 가시성\n",
    "\n",
    "### Telemetry 대상\n",
    "\n",
    "- 🖥️ **Console**: 로컬 개발 및 디버깅\n",
    "- 📊 **Aspire Dashboard**: Docker 기반 로컬 모니터링\n",
    "- ☁️ **Azure Application Insights**: 프로덕션 모니터링\n",
    "- 🔧 **기타 APM**: Prometheus, Jaeger, Grafana 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f784783",
   "metadata": {},
   "source": [
    "## 2. 환경 설정\n",
    "\n",
    "필요한 패키지를 설치하고 환경 변수를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ed0b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 설치 (이미 포함되어 있음)\n",
    "# agent-framework에 OpenTelemetry 패키지가 포함되어 있어 추가 설치 불필요\n",
    "# !pip install agent-framework agent-framework-azure-ai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05c24780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Observability 환경 변수 ===\n",
      "✓ ENABLE_OTEL: true\n",
      "   -> Observability 활성화 (true/false)\n",
      "✓ ENABLE_SENSITIVE_DATA: true\n",
      "   -> 민감한 데이터 포함 (true/false, 개발용)\n",
      "✓ OTLP_ENDPOINT: http://localhost:4317/\n",
      "   -> OTLP 엔드포인트 (Aspire Dashboard 등)\n",
      "○ APPLICATIONINSIGHTS_CONNECTION_STRING: (미설정)\n",
      "   -> Application Insights 연결 문자열\n",
      "\n",
      "=== 일반 환경 변수 ===\n",
      "✗ OPENAI_API_KEY\n",
      "✓ AZURE_AI_PROJECT_ENDPOINT\n"
     ]
    }
   ],
   "source": [
    "# 환경 변수 로드\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드 (override=True로 기존 값 덮어쓰기)\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Observability 필수 환경 변수\n",
    "observability_vars = {\n",
    "    \"ENABLE_OTEL\": \"Observability 활성화 (true/false)\",\n",
    "    \"ENABLE_SENSITIVE_DATA\": \"민감한 데이터 포함 (true/false, 개발용)\",\n",
    "    \"OTLP_ENDPOINT\": \"OTLP 엔드포인트 (Aspire Dashboard 등)\",\n",
    "    \"APPLICATIONINSIGHTS_CONNECTION_STRING\": \"Application Insights 연결 문자열\",\n",
    "}\n",
    "\n",
    "print(\"=== Observability 환경 변수 ===\")\n",
    "for var, description in observability_vars.items():\n",
    "    value = os.getenv(var)\n",
    "    status = \"✓\" if value else \"○\"\n",
    "    display_value = \"(설정됨)\" if value and \"CONNECTION\" in var else (value or \"(미설정)\")\n",
    "    print(f\"{status} {var}: {display_value}\")\n",
    "    print(f\"   -> {description}\")\n",
    "\n",
    "# 일반 환경 변수\n",
    "print(\"\\n=== 일반 환경 변수 ===\")\n",
    "required_vars = [\n",
    "    \"OPENAI_API_KEY\",\n",
    "    \"AZURE_AI_PROJECT_ENDPOINT\",\n",
    "]\n",
    "\n",
    "for var in required_vars:\n",
    "    status = \"✓\" if os.getenv(var) else \"✗\"\n",
    "    print(f\"{status} {var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a628f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Import 완료\n"
     ]
    }
   ],
   "source": [
    "# 공통 import\n",
    "import asyncio\n",
    "import datetime\n",
    "from random import randint\n",
    "from typing import Annotated\n",
    "\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.observability import get_tracer, setup_observability\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "\n",
    "from opentelemetry.trace import SpanKind\n",
    "from opentelemetry.trace.span import format_trace_id\n",
    "from pydantic import Field\n",
    "\n",
    "print(\"✓ Import 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90934d91",
   "metadata": {},
   "source": [
    "## 3. 기본 Observability 설정\n",
    "\n",
    "`setup_observability()` 함수를 사용하여 간단하게 observability를 활성화할 수 있습니다.\n",
    "\n",
    "### 3.1 도구 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a35a5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 도구 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "async def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    \"\"\"지정된 위치의 날씨를 반환합니다.\"\"\"\n",
    "    # 네트워크 호출 시뮬레이션\n",
    "    await asyncio.sleep(randint(0, 10) / 10.0)\n",
    "    conditions = [\"맑음\", \"흐림\", \"비\", \"폭풍\"]\n",
    "    return f\"{location}의 날씨는 {conditions[randint(0, 3)]}이며 최고 기온은 {randint(10, 30)}°C입니다.\"\n",
    "\n",
    "\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"현재 시간을 반환합니다.\"\"\"\n",
    "    return f\"현재 시간은 {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}입니다.\"\n",
    "\n",
    "\n",
    "print(\"✓ 도구 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79e186",
   "metadata": {},
   "source": [
    "### 3.2 환경 변수 기반 설정\n",
    "\n",
    "`setup_observability()`는 환경 변수를 기반으로 자동으로 exporter를 설정합니다:\n",
    "\n",
    "- `OTLP_ENDPOINT`: OTLP 프로토콜 사용 (Aspire Dashboard, Jaeger 등)\n",
    "- `APPLICATIONINSIGHTS_CONNECTION_STRING`: Azure Application Insights 사용\n",
    "- 둘 다 없으면: Console 출력 (기본)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e545564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Observability 설정 완료\n",
      "  - ENABLE_OTEL 또는 ENABLE_SENSITIVE_DATA가 true이면 활성화됩니다.\n",
      "  - OTLP_ENDPOINT 또는 APPLICATIONINSIGHTS_CONNECTION_STRING로 대상 지정\n",
      "  - 지정된 exporter가 없으면 Console에 출력됩니다.\n"
     ]
    }
   ],
   "source": [
    "# Observability 설정\n",
    "# 환경 변수 기반으로 자동 설정됨\n",
    "setup_observability()\n",
    "\n",
    "print(\"✓ Observability 설정 완료\")\n",
    "print(\"  - ENABLE_OTEL 또는 ENABLE_SENSITIVE_DATA가 true이면 활성화됩니다.\")\n",
    "print(\"  - OTLP_ENDPOINT 또는 APPLICATIONINSIGHTS_CONNECTION_STRING로 대상 지정\")\n",
    "print(\"  - 지정된 exporter가 없으면 Console에 출력됩니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6933e3",
   "metadata": {},
   "source": [
    "### 3.3 간단한 Observability 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f28dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 기본 Observability 테스트 ===\n",
      "\n",
      "🔍 Trace ID: 171896f9ae2fb96e3cc204c1ce96dd25\n",
      "   -> Application Insights나 Aspire Dashboard에서 이 ID로 검색 가능\n",
      "\n"
     ]
    },
    {
     "ename": "ServiceInitializationError",
     "evalue": "OpenAI API key is required. Set via 'api_key' parameter or 'OPENAI_API_KEY' environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mServiceInitializationError\u001b[39m                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   - Metrics: 토큰 사용량, 응답 시간\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# 실행\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m test_basic_observability()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mtest_basic_observability\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   -> Application Insights나 Aspire Dashboard에서 이 ID로 검색 가능\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Agent 생성\u001b[39;00m\n\u001b[32m     16\u001b[39m agent = ChatAgent(\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     chat_client=\u001b[43mOpenAIChatClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     18\u001b[39m     tools=[get_weather, get_current_time],\n\u001b[32m     19\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mWeatherAgent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m     instructions=\u001b[33m\"\u001b[39m\u001b[33m당신은 날씨와 시간을 알려주는 도움이 되는 조수입니다.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m )\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 질문 리스트\u001b[39;00m\n\u001b[32m     24\u001b[39m questions = [\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m서울의 날씨는 어때?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m지금 몇 시야?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework/openai/_chat_client.py:541\u001b[39m, in \u001b[36mOpenAIChatClient.__init__\u001b[39m\u001b[34m(self, model_id, api_key, org_id, default_headers, async_client, instruction_role, base_url, env_file_path, env_file_encoding)\u001b[39m\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceInitializationError(\u001b[33m\"\u001b[39m\u001b[33mFailed to create OpenAI settings.\u001b[39m\u001b[33m\"\u001b[39m, ex) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_client \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m openai_settings.api_key:\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceInitializationError(\n\u001b[32m    542\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOpenAI API key is required. Set via \u001b[39m\u001b[33m'\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m'\u001b[39m\u001b[33m environment variable.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    543\u001b[39m     )\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m openai_settings.chat_model_id:\n\u001b[32m    545\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceInitializationError(\n\u001b[32m    546\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOpenAI model ID is required. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    547\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSet via \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmodel_id\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mOPENAI_CHAT_MODEL_ID\u001b[39m\u001b[33m'\u001b[39m\u001b[33m environment variable.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    548\u001b[39m     )\n",
      "\u001b[31mServiceInitializationError\u001b[39m: OpenAI API key is required. Set via 'api_key' parameter or 'OPENAI_API_KEY' environment variable."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-04 09:06:28 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 0.90s.\n",
      "[2025-11-04 09:06:35 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:06:36 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 3.29s.\n",
      "[2025-11-04 09:06:39 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:06:44 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.06s.\n",
      "[2025-11-04 09:06:52 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:06:57 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.87s.\n",
      "[2025-11-04 09:07:04 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:07:09 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.86s.\n",
      "[2025-11-04 09:07:16 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:07:21 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.96s.\n",
      "[2025-11-04 09:07:27 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:07:32 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.04s.\n",
      "[2025-11-04 09:07:39 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:07:44 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.18s.\n",
      "[2025-11-04 09:07:52 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:07:57 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.92s.\n",
      "[2025-11-04 09:08:04 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:08:09 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.81s.\n",
      "[2025-11-04 09:08:16 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:08:21 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.97s.\n",
      "[2025-11-04 09:08:28 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:08:33 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.89s.\n",
      "[2025-11-04 09:08:40 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:08:45 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.98s.\n",
      "[2025-11-04 09:08:53 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:08:58 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.80s.\n",
      "[2025-11-04 09:09:01 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 4.42s.\n",
      "[2025-11-04 09:09:05 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:09:10 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.11s.\n",
      "[2025-11-04 09:09:18 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-11-04 09:09:23 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:424 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.88s.\n",
      "[2025-11-04 09:09:29 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py:416 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n"
     ]
    }
   ],
   "source": [
    "async def test_basic_observability():\n",
    "    \"\"\"기본 observability 테스트\"\"\"\n",
    "    print(\"=== 기본 Observability 테스트 ===\")\n",
    "    \n",
    "    # Custom span 생성 - 전체 시나리오를 감싸는 최상위 span\n",
    "    with get_tracer().start_as_current_span(\n",
    "        \"시나리오: 기본 Agent 채팅\",\n",
    "        kind=SpanKind.CLIENT\n",
    "    ) as current_span:\n",
    "        # Trace ID 출력 (이 ID로 전체 요청 추적 가능)\n",
    "        trace_id = format_trace_id(current_span.get_span_context().trace_id)\n",
    "        print(f\"\\n🔍 Trace ID: {trace_id}\")\n",
    "        print(\"   -> Application Insights나 Aspire Dashboard에서 이 ID로 검색 가능\\n\")\n",
    "        \n",
    "        # Agent 생성\n",
    "        agent = ChatAgent(\n",
    "            chat_client=OpenAIChatClient(),\n",
    "            tools=[get_weather, get_current_time],\n",
    "            name=\"WeatherAgent\",\n",
    "            instructions=\"당신은 날씨와 시간을 알려주는 도움이 되는 조수입니다.\",\n",
    "        )\n",
    "        \n",
    "        # 질문 리스트\n",
    "        questions = [\n",
    "            \"서울의 날씨는 어때?\",\n",
    "            \"지금 몇 시야?\",\n",
    "        ]\n",
    "        \n",
    "        for question in questions:\n",
    "            print(f\"[사용자] {question}\")\n",
    "            print(f\"[{agent.display_name}] \", end=\"\")\n",
    "            \n",
    "            # 스트리밍 응답 (각 청크가 자동으로 trace됨)\n",
    "            async for update in agent.run_stream(question):\n",
    "                if update.text:\n",
    "                    print(update.text, end=\"\")\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        print(\"\\n✓ 테스트 완료\")\n",
    "        print(\"\\n📊 수집된 Telemetry:\")\n",
    "        print(\"   - Traces: Agent 실행, Tool 호출, AI 모델 호출\")\n",
    "        print(\"   - Logs: 실행 로그, 에러 로그\")\n",
    "        print(\"   - Metrics: 토큰 사용량, 응답 시간\")\n",
    "\n",
    "# 실행\n",
    "await test_basic_observability()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064d9225",
   "metadata": {},
   "source": [
    "## 4. ChatAgent Observability\n",
    "\n",
    "ChatAgent를 사용할 때 자동으로 수집되는 telemetry를 살펴봅니다.\n",
    "\n",
    "### 4.1 Thread 기반 대화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59836c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_chat_agent_with_thread():\n",
    "    \"\"\"Thread를 사용한 다중 턴 대화 observability\"\"\"\n",
    "    print(\"=== ChatAgent with Thread Observability ===\")\n",
    "    \n",
    "    with get_tracer().start_as_current_span(\n",
    "        \"시나리오: Multi-turn 대화\",\n",
    "        kind=SpanKind.CLIENT\n",
    "    ) as current_span:\n",
    "        trace_id = format_trace_id(current_span.get_span_context().trace_id)\n",
    "        print(f\"\\n🔍 Trace ID: {trace_id}\\n\")\n",
    "        \n",
    "        # Agent 생성\n",
    "        agent = ChatAgent(\n",
    "            chat_client=OpenAIChatClient(),\n",
    "            tools=get_weather,\n",
    "            name=\"WeatherAgent\",\n",
    "            instructions=\"당신은 날씨 정보를 제공하는 전문가입니다. 사용자의 위치를 기억하세요.\",\n",
    "        )\n",
    "        \n",
    "        # Thread 생성 - 대화 컨텍스트 유지\n",
    "        thread = agent.get_new_thread()\n",
    "        \n",
    "        # 다중 턴 대화\n",
    "        questions = [\n",
    "            \"서울의 날씨는 어때?\",\n",
    "            \"거기랑 부산이랑 어디가 더 좋아?\",  # 이전 컨텍스트 활용\n",
    "            \"하늘은 왜 파래?\",  # 도구가 필요 없는 질문\n",
    "        ]\n",
    "        \n",
    "        for i, question in enumerate(questions, 1):\n",
    "            print(f\"\\n--- 턴 {i} ---\")\n",
    "            print(f\"[사용자] {question}\")\n",
    "            print(f\"[{agent.display_name}] \", end=\"\")\n",
    "            \n",
    "            # 같은 thread를 사용하여 컨텍스트 유지\n",
    "            async for update in agent.run_stream(question, thread=thread):\n",
    "                if update.text:\n",
    "                    print(update.text, end=\"\")\n",
    "            print(\"\")\n",
    "        \n",
    "        print(\"\\n✓ Multi-turn 대화 완료\")\n",
    "        print(\"\\n📊 각 턴마다 개별 span이 생성되어 전체 대화 흐름을 추적할 수 있습니다.\")\n",
    "\n",
    "# 실행\n",
    "await test_chat_agent_with_thread()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51c2303",
   "metadata": {},
   "source": [
    "## 5. Azure AI Agent Observability\n",
    "\n",
    "Azure AI를 사용할 때는 `setup_azure_ai_observability()`를 사용하여 Application Insights와 자동으로 연동됩니다.\n",
    "\n",
    "### 5.1 Azure AI Agent Client 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_azure_ai_observability():\n",
    "    \"\"\"Azure AI Agent의 자동 observability 설정\"\"\"\n",
    "    print(\"=== Azure AI Agent Observability ===\")\n",
    "    \n",
    "    # Azure AI Project가 필요합니다\n",
    "    if not os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\"):\n",
    "        print(\"⚠️  AZURE_AI_PROJECT_ENDPOINT가 설정되지 않았습니다.\")\n",
    "        print(\"   이 예제를 실행하려면 Azure AI Project가 필요합니다.\")\n",
    "        return\n",
    "    \n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential) as client,\n",
    "    ):\n",
    "        # Azure AI Project에 연결된 Application Insights로 자동 설정\n",
    "        # 이 메서드는:\n",
    "        # 1. Azure AI Project에서 Application Insights 연결 문자열을 가져옴\n",
    "        # 2. Observability를 자동으로 설정\n",
    "        # 3. 기존 설정을 덮어씀\n",
    "        await client.setup_azure_ai_observability()\n",
    "        \n",
    "        print(\"✓ Azure AI Observability 설정 완료\")\n",
    "        print(\"  -> Application Insights로 자동 연결됨\\n\")\n",
    "        \n",
    "        with get_tracer().start_as_current_span(\n",
    "            \"시나리오: Azure AI Agent 채팅\",\n",
    "            kind=SpanKind.CLIENT\n",
    "        ) as current_span:\n",
    "            trace_id = format_trace_id(current_span.get_span_context().trace_id)\n",
    "            print(f\"🔍 Trace ID: {trace_id}\")\n",
    "            print(\"   -> Azure Portal의 Application Insights에서 확인 가능\\n\")\n",
    "            \n",
    "            # Agent 생성\n",
    "            async with client.create_agent(\n",
    "                name=\"WeatherAgent\",\n",
    "                instructions=\"당신은 날씨를 알려주는 도움이 되는 조수입니다.\",\n",
    "                tools=get_weather,\n",
    "            ) as agent:\n",
    "                question = \"서울과 도쿄의 날씨를 비교해줘.\"\n",
    "                print(f\"[사용자] {question}\")\n",
    "                print(f\"[Agent] \", end=\"\")\n",
    "                \n",
    "                result = await agent.run(question)\n",
    "                print(result.text if result.text else \"No response\")\n",
    "                \n",
    "                print(\"\\n✓ Azure AI Agent 실행 완료\")\n",
    "                print(\"\\n📊 Azure Portal에서 확인할 수 있는 정보:\")\n",
    "                print(\"   - End-to-end 트랜잭션 맵\")\n",
    "                print(\"   - AI 모델 호출 상세 정보\")\n",
    "                print(\"   - 토큰 사용량 집계\")\n",
    "                print(\"   - 성능 병목 지점\")\n",
    "                print(\"   - 에러 및 예외 추적\")\n",
    "\n",
    "# 실행\n",
    "await test_azure_ai_observability()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0139ea",
   "metadata": {},
   "source": [
    "## 6. Custom Span 생성\n",
    "\n",
    "비즈니스 로직에 맞는 custom span을 생성하여 더 세밀한 추적이 가능합니다.\n",
    "\n",
    "### 6.1 함수에 Span 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53352ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_user_request(user_id: str, query: str) -> str:\n",
    "    \"\"\"사용자 요청을 처리하는 비즈니스 로직 (custom span 포함)\"\"\"\n",
    "    \n",
    "    # Custom span 생성\n",
    "    with get_tracer().start_as_current_span(\n",
    "        \"process_user_request\",\n",
    "        kind=SpanKind.INTERNAL\n",
    "    ) as span:\n",
    "        # Span에 커스텀 속성 추가\n",
    "        span.set_attribute(\"user.id\", user_id)\n",
    "        span.set_attribute(\"query.length\", len(query))\n",
    "        \n",
    "        print(f\"[처리 시작] 사용자 {user_id}의 요청 처리 중...\")\n",
    "        \n",
    "        # 1단계: 입력 검증\n",
    "        with get_tracer().start_as_current_span(\"validate_input\"):\n",
    "            if not query.strip():\n",
    "                span.set_attribute(\"validation.result\", \"failed\")\n",
    "                raise ValueError(\"빈 쿼리는 처리할 수 없습니다.\")\n",
    "            span.set_attribute(\"validation.result\", \"success\")\n",
    "            print(\"  ✓ 입력 검증 완료\")\n",
    "        \n",
    "        # 2단계: Agent 처리\n",
    "        with get_tracer().start_as_current_span(\"agent_processing\"):\n",
    "            agent = ChatAgent(\n",
    "                chat_client=OpenAIChatClient(),\n",
    "                tools=get_weather,\n",
    "                name=\"AssistantAgent\",\n",
    "                instructions=\"사용자의 질문에 도움이 되는 답변을 제공하세요.\",\n",
    "            )\n",
    "            \n",
    "            result = await agent.run(query)\n",
    "            response = result.text if result.text else \"응답 없음\"\n",
    "            print(\"  ✓ Agent 처리 완료\")\n",
    "        \n",
    "        # 3단계: 결과 후처리\n",
    "        with get_tracer().start_as_current_span(\"post_processing\"):\n",
    "            # 응답 길이 제한 (예시)\n",
    "            if len(response) > 500:\n",
    "                response = response[:500] + \"...\"\n",
    "                span.set_attribute(\"response.truncated\", True)\n",
    "            \n",
    "            span.set_attribute(\"response.length\", len(response))\n",
    "            print(\"  ✓ 후처리 완료\")\n",
    "        \n",
    "        print(\"[처리 완료]\\n\")\n",
    "        return response\n",
    "\n",
    "\n",
    "print(\"✓ Custom span 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1845a3",
   "metadata": {},
   "source": [
    "### 6.2 Custom Span 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_custom_spans():\n",
    "    \"\"\"Custom span을 사용한 세밀한 추적\"\"\"\n",
    "    print(\"=== Custom Span 예제 ===\")\n",
    "    \n",
    "    with get_tracer().start_as_current_span(\n",
    "        \"시나리오: 사용자 요청 처리 파이프라인\",\n",
    "        kind=SpanKind.CLIENT\n",
    "    ) as current_span:\n",
    "        trace_id = format_trace_id(current_span.get_span_context().trace_id)\n",
    "        print(f\"\\n🔍 Trace ID: {trace_id}\\n\")\n",
    "        \n",
    "        # 여러 사용자 요청 처리\n",
    "        requests = [\n",
    "            (\"user_001\", \"부산의 날씨가 어때?\"),\n",
    "            (\"user_002\", \"오늘 날씨 좋아?\"),\n",
    "        ]\n",
    "        \n",
    "        for user_id, query in requests:\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"사용자: {user_id}\")\n",
    "            print(f\"쿼리: {query}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            response = await process_user_request(user_id, query)\n",
    "            print(f\"[응답] {response}\\n\")\n",
    "        \n",
    "        print(\"✓ 모든 요청 처리 완료\")\n",
    "        print(\"\\n📊 Custom Span으로 추적된 정보:\")\n",
    "        print(\"   - 전체 파이프라인 (process_user_request)\")\n",
    "        print(\"   - 입력 검증 단계 (validate_input)\")\n",
    "        print(\"   - Agent 처리 단계 (agent_processing)\")\n",
    "        print(\"   - 후처리 단계 (post_processing)\")\n",
    "        print(\"   - 각 단계별 속성: user.id, query.length, response.length 등\")\n",
    "\n",
    "# 실행\n",
    "await test_custom_spans()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03811eb8",
   "metadata": {},
   "source": [
    "## 7. Workflow Observability\n",
    "\n",
    "Workflow를 사용할 때도 자동으로 telemetry가 수집됩니다.\n",
    "\n",
    "### 7.1 간단한 Workflow 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import (\n",
    "    Executor,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    handler,\n",
    ")\n",
    "from typing_extensions import Never\n",
    "\n",
    "\n",
    "class UpperCaseExecutor(Executor):\n",
    "    \"\"\"텍스트를 대문자로 변환하는 Executor\"\"\"\n",
    "\n",
    "    @handler\n",
    "    async def to_upper_case(self, text: str, ctx: WorkflowContext[str]) -> None:\n",
    "        print(f\"[UpperCaseExecutor] 입력: '{text}'\")\n",
    "        result = text.upper()\n",
    "        print(f\"[UpperCaseExecutor] 출력: '{result}'\")\n",
    "        \n",
    "        # 다음 executor로 전송\n",
    "        await ctx.send_message(result)\n",
    "\n",
    "\n",
    "class ReverseTextExecutor(Executor):\n",
    "    \"\"\"텍스트를 뒤집는 Executor\"\"\"\n",
    "\n",
    "    @handler\n",
    "    async def reverse_text(self, text: str, ctx: WorkflowContext[Never, str]) -> None:\n",
    "        print(f\"[ReverseTextExecutor] 입력: '{text}'\")\n",
    "        result = text[::-1]\n",
    "        print(f\"[ReverseTextExecutor] 출력: '{result}'\")\n",
    "        \n",
    "        # 최종 결과 출력\n",
    "        await ctx.yield_output(result)\n",
    "\n",
    "\n",
    "print(\"✓ Workflow Executor 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fcf57a",
   "metadata": {},
   "source": [
    "### 7.2 Workflow Observability 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d32c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_workflow_observability():\n",
    "    \"\"\"Workflow의 자동 telemetry 수집\"\"\"\n",
    "    print(\"=== Workflow Observability 예제 ===\")\n",
    "    \n",
    "    with get_tracer().start_as_current_span(\n",
    "        \"시나리오: Sequential Workflow\",\n",
    "        kind=SpanKind.CLIENT\n",
    "    ) as current_span:\n",
    "        trace_id = format_trace_id(current_span.get_span_context().trace_id)\n",
    "        print(f\"\\n🔍 Trace ID: {trace_id}\\n\")\n",
    "        \n",
    "        # Executor 생성\n",
    "        upper_case_executor = UpperCaseExecutor(id=\"upper_case_executor\")\n",
    "        reverse_text_executor = ReverseTextExecutor(id=\"reverse_text_executor\")\n",
    "        \n",
    "        # Workflow 구성\n",
    "        workflow = (\n",
    "            WorkflowBuilder()\n",
    "            .add_edge(upper_case_executor, reverse_text_executor)\n",
    "            .set_start_executor(upper_case_executor)\n",
    "            .build()\n",
    "        )\n",
    "        \n",
    "        # Workflow 실행\n",
    "        input_text = \"hello world\"\n",
    "        print(f\"입력 텍스트: '{input_text}'\\n\")\n",
    "        \n",
    "        async for event in workflow.run_stream(input_text):\n",
    "            if hasattr(event, 'output'):\n",
    "                print(f\"\\n최종 결과: '{event.output}'\")\n",
    "        \n",
    "        print(\"\\n✓ Workflow 실행 완료\")\n",
    "        print(\"\\n📊 Workflow Telemetry:\")\n",
    "        print(\"   - Workflow 빌드 span\")\n",
    "        print(\"   - Workflow 실행 span\")\n",
    "        print(\"   - 각 Executor 처리 span\")\n",
    "        print(\"   - Executor 간 메시지 전송 추적\")\n",
    "        print(\"   - End-to-end 가시성 제공\")\n",
    "\n",
    "# 실행\n",
    "await test_workflow_observability()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6755dc3f",
   "metadata": {},
   "source": [
    "## 8. Application Insights 연동\n",
    "\n",
    "Azure Application Insights를 사용하여 프로덕션 환경에서 AI 애플리케이션을 모니터링할 수 있습니다.\n",
    "\n",
    "### 8.1 설정 방법\n",
    "\n",
    "#### 방법 1: 환경 변수 사용\n",
    "\n",
    "`.env` 파일에 다음을 추가:\n",
    "\n",
    "```bash\n",
    "ENABLE_OTEL=true\n",
    "APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=...;IngestionEndpoint=...\n",
    "```\n",
    "\n",
    "그 다음 `setup_observability()`만 호출하면 자동으로 Application Insights로 전송됩니다.\n",
    "\n",
    "#### 방법 2: Azure AI Agent Client 사용\n",
    "\n",
    "```python\n",
    "async with AzureAIAgentClient(async_credential=credential) as client:\n",
    "    # Azure AI Project에 연결된 Application Insights 자동 설정\n",
    "    await client.setup_azure_ai_observability()\n",
    "```\n",
    "\n",
    "### 8.2 Application Insights에서 확인할 수 있는 정보\n",
    "\n",
    "1. **Application Map** 🗺️\n",
    "   - 전체 시스템 아키텍처 시각화\n",
    "   - 서비스 간 의존성 파악\n",
    "   - 병목 지점 식별\n",
    "\n",
    "2. **Performance** ⚡\n",
    "   - 요청별 응답 시간\n",
    "   - AI 모델 호출 지연 시간\n",
    "   - Tool 실행 성능\n",
    "\n",
    "3. **Failures** ❌\n",
    "   - 에러 발생 빈도\n",
    "   - 예외 스택 추적\n",
    "   - 실패율 트렌드\n",
    "\n",
    "4. **Logs** 📝\n",
    "   - 구조화된 로그 쿼리 (Kusto)\n",
    "   - 컨텍스트 정보 포함\n",
    "   - Trace ID 기반 필터링\n",
    "\n",
    "5. **Custom Metrics** 📊\n",
    "   - 토큰 사용량 추적\n",
    "   - 비용 모니터링\n",
    "   - 사용자별 통계\n",
    "\n",
    "### 8.3 Kusto 쿼리 예시\n",
    "\n",
    "```kusto\n",
    "// 특정 Trace ID로 전체 요청 추적\n",
    "traces\n",
    "| where operation_Id == \"your-trace-id\"\n",
    "| order by timestamp asc\n",
    "\n",
    "// AI 모델 호출 성능 분석\n",
    "dependencies\n",
    "| where type == \"AI\"\n",
    "| summarize avg(duration), count() by name\n",
    "\n",
    "// 토큰 사용량 집계\n",
    "customMetrics\n",
    "| where name == \"gen_ai.client.token.usage\"\n",
    "| summarize total_tokens=sum(value) by bin(timestamp, 1h)\n",
    "\n",
    "// 에러율 트렌드\n",
    "requests\n",
    "| summarize \n",
    "    total=count(), \n",
    "    failures=countif(success == false),\n",
    "    error_rate=100.0 * countif(success == false) / count()\n",
    "  by bin(timestamp, 1h)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d800ae9",
   "metadata": {},
   "source": [
    "## 9. Aspire Dashboard 사용하기\n",
    "\n",
    "로컬 개발 시 Aspire Dashboard를 사용하면 Application Insights 없이도 telemetry를 시각화할 수 있습니다.\n",
    "\n",
    "### 9.1 Aspire Dashboard 시작\n",
    "\n",
    "터미널에서 실행:\n",
    "\n",
    "```bash\n",
    "# Docker를 사용하여 Aspire Dashboard 시작\n",
    "docker run --rm -it \\\n",
    "  -p 18888:18888 \\\n",
    "  -p 4317:18889 \\\n",
    "  --name aspire-dashboard \\\n",
    "  mcr.microsoft.com/dotnet/aspire-dashboard:9.0\n",
    "```\n",
    "\n",
    "브라우저에서 `http://localhost:18888` 접속\n",
    "\n",
    "### 9.2 환경 변수 설정\n",
    "\n",
    "`.env` 파일:\n",
    "\n",
    "```bash\n",
    "ENABLE_OTEL=true\n",
    "ENABLE_SENSITIVE_DATA=true  # 개발 환경에서만!\n",
    "OTLP_ENDPOINT=http://localhost:4317\n",
    "```\n",
    "\n",
    "### 9.3 Aspire Dashboard 특징\n",
    "\n",
    "✅ **Traces 탭**: 전체 요청 추적, Span 계층 구조  \n",
    "✅ **Metrics 탭**: 실시간 메트릭 차트  \n",
    "✅ **Logs 탭**: 구조화된 로그 검색  \n",
    "✅ **Structured 탭**: 속성 기반 필터링  \n",
    "✅ **No Azure Required**: 완전 로컬 환경  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46d4a48",
   "metadata": {},
   "source": [
    "## 요약 및 베스트 프랙티스\n",
    "\n",
    "### Observability 핵심 개념\n",
    "\n",
    "1. **OpenTelemetry 3대 요소**\n",
    "   - Traces: 요청 경로 추적\n",
    "   - Logs: 이벤트 기록\n",
    "   - Metrics: 수치 데이터\n",
    "\n",
    "2. **자동 계측**\n",
    "   - Agent Framework가 자동으로 telemetry 생성\n",
    "   - GenAI Semantic Conventions 준수\n",
    "   - 토큰 사용량, 응답 시간 자동 추적\n",
    "\n",
    "3. **설정 방법**\n",
    "   - `setup_observability()`: 환경 변수 기반 자동 설정\n",
    "   - `setup_azure_ai_observability()`: Azure AI 자동 연동\n",
    "   - Manual setup: 커스텀 exporter 설정\n",
    "\n",
    "### 베스트 프랙티스\n",
    "\n",
    "#### 1. 환경별 설정\n",
    "\n",
    "```python\n",
    "# ✓ Good: 개발 환경\n",
    "# .env\n",
    "ENABLE_OTEL=true\n",
    "ENABLE_SENSITIVE_DATA=true  # 개발에서만!\n",
    "OTLP_ENDPOINT=http://localhost:4317  # Aspire Dashboard\n",
    "\n",
    "# ✓ Good: 프로덕션 환경\n",
    "# .env\n",
    "ENABLE_OTEL=true\n",
    "ENABLE_SENSITIVE_DATA=false  # 프로덕션에서는 false!\n",
    "APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=...\n",
    "```\n",
    "\n",
    "#### 2. Custom Span 사용\n",
    "\n",
    "```python\n",
    "# ✓ Good: 비즈니스 로직에 의미 있는 span 추가\n",
    "with get_tracer().start_as_current_span(\n",
    "    \"process_payment\",\n",
    "    kind=SpanKind.INTERNAL\n",
    ") as span:\n",
    "    span.set_attribute(\"payment.amount\", amount)\n",
    "    span.set_attribute(\"payment.currency\", \"USD\")\n",
    "    # 비즈니스 로직\n",
    "\n",
    "# ✗ Bad: 너무 세밀한 span은 오버헤드 증가\n",
    "with get_tracer().start_as_current_span(\"add_two_numbers\"):\n",
    "    result = a + b  # 불필요함\n",
    "```\n",
    "\n",
    "#### 3. Trace ID 활용\n",
    "\n",
    "```python\n",
    "# ✓ Good: 사용자에게 Trace ID 제공\n",
    "with get_tracer().start_as_current_span(\"user_request\") as span:\n",
    "    trace_id = format_trace_id(span.get_span_context().trace_id)\n",
    "    print(f\"요청 ID: {trace_id}\")\n",
    "    # 사용자가 이 ID로 지원팀에 문의 가능\n",
    "```\n",
    "\n",
    "#### 4. 민감한 데이터 관리\n",
    "\n",
    "```python\n",
    "# ✓ Good: 프로덕션에서는 민감한 데이터 비활성화\n",
    "if os.getenv(\"ENVIRONMENT\") == \"production\":\n",
    "    # ENABLE_SENSITIVE_DATA=false\n",
    "    # 프롬프트와 응답 내용이 로깅되지 않음\n",
    "    pass\n",
    "\n",
    "# ✗ Bad: 프로덕션에서 민감한 데이터 활성화\n",
    "# ENABLE_SENSITIVE_DATA=true  # 절대 안 됨!\n",
    "```\n",
    "\n",
    "#### 5. 로그 레벨 설정\n",
    "\n",
    "```python\n",
    "# ✓ Good: 환경별 로그 레벨\n",
    "import logging\n",
    "\n",
    "if os.getenv(\"ENVIRONMENT\") == \"development\":\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "else:\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "```\n",
    "\n",
    "### 모니터링 전략\n",
    "\n",
    "| 환경 | Observability 도구 | 설정 |\n",
    "|------|------------------|------|\n",
    "| 로컬 개발 | Aspire Dashboard | OTLP_ENDPOINT |\n",
    "| 개발/스테이징 | Application Insights | APPLICATIONINSIGHTS_CONNECTION_STRING |\n",
    "| 프로덕션 | Application Insights + 알림 | 모든 telemetry + 알림 규칙 |\n",
    "| CI/CD | Console Output | ENABLE_OTEL=true (exporter 없음) |\n",
    "\n",
    "### 알림 설정 (Application Insights)\n",
    "\n",
    "프로덕션에서 설정할 알림:\n",
    "\n",
    "1. **에러율**: 5분간 에러율 > 5%\n",
    "2. **응답 시간**: P95 > 3초\n",
    "3. **토큰 사용량**: 시간당 토큰 > 임계값\n",
    "4. **가용성**: 가동 시간 < 99%\n",
    "\n",
    "### 다음 단계\n",
    "\n",
    "1. **Aspire Dashboard 설정**: 로컬 개발 환경 구축\n",
    "2. **Custom Attributes**: 비즈니스 메트릭 추가\n",
    "3. **Application Insights**: Azure 환경 연동\n",
    "4. **알림 규칙**: 프로덕션 모니터링 설정\n",
    "5. **대시보드 구축**: Kusto 쿼리로 커스텀 대시보드\n",
    "6. **비용 최적화**: 토큰 사용량 분석 및 최적화\n",
    "\n",
    "### 참고 자료\n",
    "\n",
    "- [Azure Monitor OpenTelemetry](https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-overview)\n",
    "- [Aspire Dashboard](https://learn.microsoft.com/dotnet/aspire/fundamentals/dashboard/overview)\n",
    "- [OpenTelemetry Python](https://opentelemetry.io/docs/languages/python/)\n",
    "- [GenAI Semantic Conventions](https://opentelemetry.io/docs/specs/semconv/gen-ai/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maf-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
