{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0d9e2f",
   "metadata": {},
   "source": [
    "# ì¥ê¸° ì»¨í…ìŠ¤íŠ¸ ê¸°ì–µ(Long-term Memory)\n",
    "\n",
    "ì´ ì›Œí¬ìƒµì—ì„œëŠ” Agent Frameworkì—ì„œ ì¥ê¸° ì»¨í…ìŠ¤íŠ¸ ê¸°ì–µì„ êµ¬í˜„í•˜ëŠ” ë‹¤ì–‘í•œ ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [í™˜ê²½ ì„¤ì •](#í™˜ê²½-ì„¤ì •)\n",
    "2. [ê°„ë‹¨í•œ ì»¤ìŠ¤í…€ Context Provider](#ê°„ë‹¨í•œ-ì»¤ìŠ¤í…€-context-provider)\n",
    "3. [Mem0 Context Provider](#mem0-context-provider)\n",
    "4. [Redis Context Provider](#redis-context-provider)\n",
    "5. [Thread ê´€ë¦¬ ë° ìŠ¤ì½”í•‘](#thread-ê´€ë¦¬-ë°-ìŠ¤ì½”í•‘)\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- Context Providerì˜ ê°œë…ê³¼ ì‘ë™ ë°©ì‹ ì´í•´\n",
    "- ì»¤ìŠ¤í…€ Context Provider êµ¬í˜„ ë°©ë²• í•™ìŠµ\n",
    "- Mem0ì™€ Redisë¥¼ í™œìš©í•œ ì˜êµ¬ ë©”ëª¨ë¦¬ êµ¬í˜„\n",
    "- Thread ìŠ¤ì½”í•‘ ì „ëµ ì´í•´"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34719b92",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •\n",
    "\n",
    "í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "239d85b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "# !pip install agent-framework agent-framework-azure-ai agent-framework-mem0 agent-framework-redis python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f8cb1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜:\n",
      "âœ“ AZURE_AI_PROJECT_ENDPOINT\n",
      "âœ“ AZURE_AI_MODEL_DEPLOYMENT_NAME\n",
      "\n",
      "ì„ íƒ í™˜ê²½ ë³€ìˆ˜:\n",
      "âœ“ MEM0_API_KEY\n",
      "âœ— OPENAI_API_KEY\n",
      "\n",
      "Mem0ìš© Azure OpenAI í™˜ê²½ ë³€ìˆ˜:\n",
      "âœ“ LLM_AZURE_OPENAI_API_KEY: 6hB...Teh\n",
      "âœ“ LLM_AZURE_DEPLOYMENT: gpt-4.1\n",
      "âœ“ LLM_AZURE_ENDPOINT: https://aistudioaiservices343274518006.openai.azure.com\n",
      "âœ“ LLM_AZURE_API_VERSION: 2024-10-21\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (override=Trueë¡œ ê¸°ì¡´ ê°’ ë®ì–´ì“°ê¸°)\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Mem0ì— í•„ìš”í•œ Azure OpenAI í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "os.environ[\"LLM_AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\", \"\")\n",
    "os.environ[\"LLM_AZURE_DEPLOYMENT\"] = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\", \"\")\n",
    "os.environ[\"LLM_AZURE_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"\")\n",
    "os.environ[\"LLM_AZURE_API_VERSION\"] = \"2024-10-21\"\n",
    "\n",
    "# í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "required_vars = [\n",
    "    \"AZURE_AI_PROJECT_ENDPOINT\",\n",
    "    \"AZURE_AI_MODEL_DEPLOYMENT_NAME\",\n",
    "]\n",
    "\n",
    "optional_vars = [\n",
    "    \"MEM0_API_KEY\",  # Mem0 Platform ì‚¬ìš© ì‹œ\n",
    "    \"OPENAI_API_KEY\",  # Mem0 OSS ë˜ëŠ” Redis ë²¡í„° ê²€ìƒ‰ ì‚¬ìš© ì‹œ\n",
    "]\n",
    "\n",
    "print(\"í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜:\")\n",
    "for var in required_vars:\n",
    "    status = \"âœ“\" if os.getenv(var) else \"âœ—\"\n",
    "    print(f\"{status} {var}\")\n",
    "\n",
    "print(\"\\nì„ íƒ í™˜ê²½ ë³€ìˆ˜:\")\n",
    "for var in optional_vars:\n",
    "    status = \"âœ“\" if os.getenv(var) else \"âœ—\"\n",
    "    print(f\"{status} {var}\")\n",
    "\n",
    "print(\"\\nMem0ìš© Azure OpenAI í™˜ê²½ ë³€ìˆ˜:\")\n",
    "mem0_vars = [\n",
    "    \"LLM_AZURE_OPENAI_API_KEY\",\n",
    "    \"LLM_AZURE_DEPLOYMENT\", \n",
    "    \"LLM_AZURE_ENDPOINT\",\n",
    "    \"LLM_AZURE_API_VERSION\"\n",
    "]\n",
    "for var in mem0_vars:\n",
    "    value = os.getenv(var, \"\")\n",
    "    status = \"âœ“\" if value else \"âœ—\"\n",
    "    # API í‚¤ëŠ” ë§ˆìŠ¤í‚¹í•´ì„œ í‘œì‹œ\n",
    "    if \"API_KEY\" in var and value:\n",
    "        display_value = f\"{value[:3]}...{value[-3:]}\"\n",
    "    elif value:\n",
    "        display_value = value\n",
    "    else:\n",
    "        display_value = \"Not set\"\n",
    "    print(f\"{status} {var}: {display_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69406ab1",
   "metadata": {},
   "source": [
    "## 2. ê°„ë‹¨í•œ ì»¤ìŠ¤í…€ Context Provider\n",
    "\n",
    "ë¨¼ì € ê°„ë‹¨í•œ ì»¤ìŠ¤í…€ Context Providerë¥¼ ë§Œë“¤ì–´ ê¸°ë³¸ ê°œë…ì„ ì´í•´í•´ë´…ì‹œë‹¤.\n",
    "ì´ ì˜ˆì œëŠ” ì‚¬ìš©ìì˜ ì´ë¦„ê³¼ ë‚˜ì´ë¥¼ ê¸°ì–µí•˜ëŠ” ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a887a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ UserInfoMemory Context Provider ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "from collections.abc import MutableSequence, Sequence\n",
    "from typing import Any\n",
    "\n",
    "from agent_framework import ChatAgent, ChatClientProtocol, ChatMessage, ChatOptions, Context, ContextProvider\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class UserInfo(BaseModel):\n",
    "    \"\"\"ì‚¬ìš©ì ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ëª¨ë¸\"\"\"\n",
    "    name: str | None = None\n",
    "    age: int | None = None\n",
    "\n",
    "\n",
    "class UserInfoMemory(ContextProvider):\n",
    "    \"\"\"ì‚¬ìš©ì ì •ë³´ë¥¼ ê¸°ì–µí•˜ëŠ” Context Provider\"\"\"\n",
    "    \n",
    "    def __init__(self, chat_client: ChatClientProtocol, user_info: UserInfo | None = None, **kwargs: Any):\n",
    "        self._chat_client = chat_client\n",
    "        if user_info:\n",
    "            self.user_info = user_info\n",
    "        elif kwargs:\n",
    "            self.user_info = UserInfo.model_validate(kwargs)\n",
    "        else:\n",
    "            self.user_info = UserInfo()\n",
    "\n",
    "    async def invoked(\n",
    "        self,\n",
    "        request_messages: ChatMessage | Sequence[ChatMessage],\n",
    "        response_messages: ChatMessage | Sequence[ChatMessage] | None = None,\n",
    "        invoke_exception: Exception | None = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"ì—ì´ì „íŠ¸ í˜¸ì¶œ í›„ ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        user_messages = [\n",
    "            msg for msg in request_messages \n",
    "            if hasattr(msg, \"role\") and msg.role.value == \"user\"\n",
    "        ]\n",
    "\n",
    "        if (self.user_info.name is None or self.user_info.age is None) and user_messages:\n",
    "            try:\n",
    "                result = await self._chat_client.get_response(\n",
    "                    messages=request_messages,\n",
    "                    chat_options=ChatOptions(\n",
    "                        instructions=\"Extract the user's name and age from the message if present. If not present return nulls.\",\n",
    "                        response_format=UserInfo,\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "                if result.value and isinstance(result.value, UserInfo):\n",
    "                    if result.value.name:\n",
    "                        self.user_info.name = result.value.name\n",
    "                    if result.value.age:\n",
    "                        self.user_info.age = result.value.age\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    async def invoking(self, messages: ChatMessage | MutableSequence[ChatMessage], **kwargs: Any) -> Context:\n",
    "        \"\"\"ì—ì´ì „íŠ¸ í˜¸ì¶œ ì „ ì»¨í…ìŠ¤íŠ¸ ì œê³µ\"\"\"\n",
    "        instructions: list[str] = []\n",
    "\n",
    "        if self.user_info.name is None:\n",
    "            instructions.append(\n",
    "                \"Ask the user for their name and politely decline to answer any questions until they provide it.\"\n",
    "            )\n",
    "        else:\n",
    "            instructions.append(f\"The user's name is {self.user_info.name}.\")\n",
    "\n",
    "        if self.user_info.age is None:\n",
    "            instructions.append(\n",
    "                \"Ask the user for their age and politely decline to answer any questions until they provide it.\"\n",
    "            )\n",
    "        else:\n",
    "            instructions.append(f\"The user's age is {self.user_info.age}.\")\n",
    "\n",
    "        return Context(instructions=\" \".join(instructions))\n",
    "\n",
    "    def serialize(self) -> str:\n",
    "        \"\"\"Thread ì˜ì†ì„±ì„ ìœ„í•œ ì§ë ¬í™”\"\"\"\n",
    "        return self.user_info.model_dump_json()\n",
    "\n",
    "\n",
    "print(\"âœ“ UserInfoMemory Context Provider ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a8c4dc",
   "metadata": {},
   "source": [
    "### ì»¤ìŠ¤í…€ Context Provider í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì´ì œ ë§Œë“  Context Providerë¥¼ ì‹¤ì œë¡œ ì‚¬ìš©í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31d1a133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì‚¬ìš©ì] Hello, what is the square root of 9?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-04 13:44:06 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework/_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì—ì´ì „íŠ¸] Hello! Before I answer your question, may I please know your name? Also, could you tell me your age? Iâ€™d be happy to help with your question once I have this information.\n",
      "\n",
      "[ì‚¬ìš©ì] My name is ì§€í›ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-04 13:44:12 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework/_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì—ì´ì „íŠ¸] Thank you, ì§€í›ˆ! Could you please let me know your age as well? Once you do, I'll be happy to answer your question about the square root of 9.\n",
      "\n",
      "[ì‚¬ìš©ì] I am 25 years old\n",
      "[ì—ì´ì „íŠ¸] Thank you for sharing, ì§€í›ˆ! Since you are 25 years old, I can now answer your question.\n",
      "\n",
      "The square root of 9 is 3. If you have any more questions, feel free to ask, ì§€í›ˆ!\n",
      "\n",
      "=== ì €ì¥ëœ ì‚¬ìš©ì ì •ë³´ ===\n",
      "ì´ë¦„: ì§€í›ˆ\n",
      "ë‚˜ì´: 25\n"
     ]
    }
   ],
   "source": [
    "async def test_custom_context_provider():\n",
    "    \"\"\"ì»¤ìŠ¤í…€ Context Provider í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    async with AzureCliCredential() as credential:\n",
    "        chat_client = AzureAIAgentClient(async_credential=credential)\n",
    "        memory_provider = UserInfoMemory(chat_client)\n",
    "\n",
    "        async with ChatAgent(\n",
    "            chat_client=chat_client,\n",
    "            instructions=\"You are a friendly assistant. Always address the user by their name.\",\n",
    "            context_providers=memory_provider,\n",
    "        ) as agent:\n",
    "            thread = agent.get_new_thread()\n",
    "\n",
    "            # ì²« ë²ˆì§¸ ì§ˆë¬¸ - ì´ë¦„ê³¼ ë‚˜ì´ë¥¼ ëª¨ë¥´ëŠ” ìƒíƒœ\n",
    "            print(\"[ì‚¬ìš©ì] Hello, what is the square root of 9?\")\n",
    "            response = await agent.run(\"Hello, what is the square root of 9?\", thread=thread)\n",
    "            print(f\"[ì—ì´ì „íŠ¸] {response}\\n\")\n",
    "\n",
    "            # ì´ë¦„ ì œê³µ\n",
    "            print(\"[ì‚¬ìš©ì] My name is ì§€í›ˆ\")\n",
    "            response = await agent.run(\"My name is ì§€í›ˆ\", thread=thread)\n",
    "            print(f\"[ì—ì´ì „íŠ¸] {response}\\n\")\n",
    "\n",
    "            # ë‚˜ì´ ì œê³µ\n",
    "            print(\"[ì‚¬ìš©ì] I am 25 years old\")\n",
    "            response = await agent.run(\"I am 25 years old\", thread=thread)\n",
    "            print(f\"[ì—ì´ì „íŠ¸] {response}\\n\")\n",
    "\n",
    "            # ë©”ëª¨ë¦¬ í™•ì¸\n",
    "            user_info_memory = thread.context_provider.providers[0]\n",
    "            print(\"=== ì €ì¥ëœ ì‚¬ìš©ì ì •ë³´ ===\")\n",
    "            print(f\"ì´ë¦„: {user_info_memory.user_info.name}\")\n",
    "            print(f\"ë‚˜ì´: {user_info_memory.user_info.age}\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await test_custom_context_provider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a129f55",
   "metadata": {},
   "source": [
    "## 3. Mem0 Context Provider\n",
    "\n",
    "Mem0ëŠ” LLMì„ ìœ„í•œ ìê°€ ê°œì„  ë©”ëª¨ë¦¬ ë ˆì´ì–´ë¡œ, ëŒ€í™” ì„¸ì…˜ ê°„ ì¥ê¸° ë©”ëª¨ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "### 3.1 ê¸°ë³¸ Mem0 ì‚¬ìš©ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc1afc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Mem0 Context Provider ê¸°ë³¸ ì˜ˆì œ ===\n",
      "Application ID: workshop_app\n",
      "Agent ID: demo_agent\n",
      "User ID: a5274b8c-4cf1-4226-95a6-209def8bdc74\n",
      "\n",
      "\n",
      "[ì‚¬ìš©ì] Please retrieve my company report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework_mem0/_provider.py:124: DeprecationWarning: output_format='v1.0' is deprecated therefore setting it to 'v1.1' by default. Check out the docs for more information: https://docs.mem0.ai/platform/quickstart#4-1-create-memories\n",
      "  await self.mem0_client.add(  # type: ignore[misc]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì—ì´ì „íŠ¸] Could you please provide your company code? This will help me locate and retrieve your company report. If you need a detailed report, please let me know as well!\n",
      "\n",
      "[ì‚¬ìš©ì] I always work with CNTS and I always want a detailed report format. Please remember and retrieve it.\n",
      "[ì—ì´ì „íŠ¸] Got it! You work with CNTS and always want the detailed report format.\n",
      "\n",
      "I'll remember this preference for future requests. If you want to retrieve the CNTS detailed report now, let me know!\n",
      "\n",
      "\n",
      "=== ìƒˆë¡œìš´ Threadì—ì„œ ìš”ì²­ ===\n",
      "[ì‚¬ìš©ì] Please retrieve my company report\n",
      "[ì—ì´ì „íŠ¸] Could you please provide the company code for your company? That will help me retrieve the correct report for you. If youâ€™d like a detailed report, let me know as well!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import os\n",
    "\n",
    "from agent_framework.mem0 import Mem0Provider\n",
    "from mem0 import AsyncMemoryClient\n",
    "\n",
    "# AsyncMemoryClientë¥¼ ì‚¬ìš©í•´ì•¼ ë¹„ë™ê¸° ì‘ì—…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤\n",
    "mem_client = AsyncMemoryClient(api_key=os.getenv(\"MEM0_API_KEY\"))\n",
    "\n",
    "def retrieve_company_report(company_code: str, detailed: bool) -> str:\n",
    "    \"\"\"íšŒì‚¬ ë³´ê³ ì„œ ì¡°íšŒ ë„êµ¬\"\"\"\n",
    "    if company_code != \"CNTS\":\n",
    "        raise ValueError(\"Company code not found\")\n",
    "    if not detailed:\n",
    "        return \"CNTS is a company that specializes in technology.\"\n",
    "    return (\n",
    "        \"CNTS is a company that specializes in technology. \"\n",
    "        \"It had a revenue of $10 million in 2022. It has 100 employees.\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "async def test_mem0_basic():\n",
    "    \"\"\"Mem0 ê¸°ë³¸ ì‚¬ìš© ì˜ˆì œ\"\"\"\n",
    "    print(\"=== Mem0 Context Provider ê¸°ë³¸ ì˜ˆì œ ===\")\n",
    "    \n",
    "    # Mem0 v2 APIëŠ” application_idì™€ agent_idê°€ í•„ìˆ˜ì…ë‹ˆë‹¤\n",
    "    application_id = \"workshop_app\"\n",
    "    agent_id = \"demo_agent\"\n",
    "    user_id = str(uuid.uuid4())\n",
    "    \n",
    "    print(f\"Application ID: {application_id}\")\n",
    "    print(f\"Agent ID: {agent_id}\")\n",
    "    print(f\"User ID: {user_id}\\n\")\n",
    "\n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential).create_agent(\n",
    "            name=\"FriendlyAssistant\",\n",
    "            instructions=\"You are a friendly assistant.\",\n",
    "            tools=retrieve_company_report,\n",
    "            context_providers=Mem0Provider(\n",
    "                application_id=application_id,\n",
    "                agent_id=agent_id,\n",
    "                user_id=user_id, \n",
    "                mem0_client=mem_client\n",
    "            ),\n",
    "        ) as agent,\n",
    "    ):\n",
    "        # ì²« ë²ˆì§¸ ì§ˆë¬¸ - íšŒì‚¬ ì½”ë“œì™€ ë³´ê³ ì„œ í˜•ì‹ì„ ëª¨ë¥´ëŠ” ìƒíƒœ\n",
    "        print(\"\\n[ì‚¬ìš©ì] Please retrieve my company report\")\n",
    "        result = await agent.run(\"Please retrieve my company report\")\n",
    "        print(f\"[ì—ì´ì „íŠ¸] {result}\\n\")\n",
    "\n",
    "        # íšŒì‚¬ ì½”ë“œì™€ ë³´ê³ ì„œ í˜•ì‹ ì•Œë ¤ì£¼ê¸°\n",
    "        query = \"I always work with CNTS and I always want a detailed report format. Please remember and retrieve it.\"\n",
    "        print(f\"[ì‚¬ìš©ì] {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"[ì—ì´ì „íŠ¸] {result}\\n\")\n",
    "\n",
    "        print(\"\\n=== ìƒˆë¡œìš´ Threadì—ì„œ ìš”ì²­ ===\")\n",
    "        # ìƒˆ thread ìƒì„± (ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ)\n",
    "        thread = agent.get_new_thread()\n",
    "\n",
    "        # Mem0ê°€ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ ê¸°ì–µí•˜ë¯€ë¡œ ëª…í™•íˆ ì„¤ëª… ì—†ì´ë„ ì‘ë™\n",
    "        print(\"[ì‚¬ìš©ì] Please retrieve my company report\")\n",
    "        result = await agent.run(\"Please retrieve my company report\", thread=thread)\n",
    "        print(f\"[ì—ì´ì „íŠ¸] {result}\\n\")\n",
    "\n",
    "# ì‹¤í–‰ (MEM0_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•¨)\n",
    "if os.getenv(\"MEM0_API_KEY\"):\n",
    "    await test_mem0_basic()\n",
    "else:\n",
    "    print(\"âš ï¸  MEM0_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Mem0 Platformì„ ì‚¬ìš©í•˜ë ¤ë©´ API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f31c84e",
   "metadata": {},
   "source": [
    "## 4. Redis Context Provider\n",
    "\n",
    "Apple siliconì—ì„œ Redis HSNWê¸°ëŠ¥ì— ë²„ê·¸ ìˆìŒ (í…ŒìŠ¤íŠ¸ ì•ˆë¨ as of 2025-11-04)\n",
    "\n",
    "Redis Context ProviderëŠ” Redis(RediSearch)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜êµ¬ì ì´ê³  ê²€ìƒ‰ ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ê³¼ ë²¡í„° ì„ë² ë”©ì„ ì‚¬ìš©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "### 4.1 Redis ì—°ê²° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c37b726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Redis Stack Docker ì»¨í…Œì´ë„ˆê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "Container ID: 37fad9df79da5e49bc17a1fd2e3dd1b95bd6f82baa1185633e7946feaab42f0a\n",
      "\n",
      "ì»¨í…Œì´ë„ˆ ìƒíƒœ:\n",
      "NAMES     STATUS                  PORTS\n",
      "redis     Up Less than a second   0.0.0.0:6379->6379/tcp\n",
      "\n",
      "\n",
      "ğŸ’¡ Redis Stackì€ ë‹¤ìŒ ëª¨ë“ˆì„ í¬í•¨í•©ë‹ˆë‹¤:\n",
      "  - RediSearch: ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ë° ë²¡í„° ê²€ìƒ‰\n",
      "  - RedisJSON: JSON ë°ì´í„° íƒ€ì… ì§€ì›\n",
      "  - RedisTimeSeries: ì‹œê³„ì—´ ë°ì´í„° ì§€ì›\n"
     ]
    }
   ],
   "source": [
    "# Redis Stack Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰\n",
    "# Redis Stackì€ RediSearch, RedisJSON ë“±ì˜ ëª¨ë“ˆì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    # ê¸°ì¡´ redis ì»¨í…Œì´ë„ˆê°€ ìˆìœ¼ë©´ ì‚­ì œ\n",
    "    subprocess.run([\"docker\", \"rm\", \"-f\", \"redis\"], capture_output=True, check=False)\n",
    "    \n",
    "    # Redis Stack ì»¨í…Œì´ë„ˆ ì‹¤í–‰ (RediSearch í¬í•¨)\n",
    "    result = subprocess.run(\n",
    "        [\"docker\", \"run\", \"--name\", \"redis\", \"-p\", \"6379:6379\", \"-d\", \"redis/redis-stack-server:latest\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        check=True\n",
    "    )\n",
    "    print(\"âœ“ Redis Stack Docker ì»¨í…Œì´ë„ˆê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"Container ID: {result.stdout.strip()}\")\n",
    "    \n",
    "    # ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸\n",
    "    status_result = subprocess.run(\n",
    "        [\"docker\", \"ps\", \"--filter\", \"name=redis\", \"--format\", \"table {{.Names}}\\t{{.Status}}\\t{{.Ports}}\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        check=True\n",
    "    )\n",
    "    print(\"\\nì»¨í…Œì´ë„ˆ ìƒíƒœ:\")\n",
    "    print(status_result.stdout)\n",
    "    \n",
    "    print(\"\\nğŸ’¡ Redis Stackì€ ë‹¤ìŒ ëª¨ë“ˆì„ í¬í•¨í•©ë‹ˆë‹¤:\")\n",
    "    print(\"  - RediSearch: ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ë° ë²¡í„° ê²€ìƒ‰\")\n",
    "    print(\"  - RedisJSON: JSON ë°ì´í„° íƒ€ì… ì§€ì›\")\n",
    "    print(\"  - RedisTimeSeries: ì‹œê³„ì—´ ë°ì´í„° ì§€ì›\")\n",
    "    \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"âš ï¸  Redis ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    print(f\"Error output: {e.stderr}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸  Dockerê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šê±°ë‚˜ ì‹¤í–‰ ì¤‘ì´ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    print(\"Docker Desktopì„ ì„¤ì¹˜í•˜ê³  ì‹¤í–‰í•œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb6c0fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Redis í—¬í¼ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# Redisê°€ localhost:6379ì—ì„œ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤\n",
    "# Dockerë¡œ ì‹¤í–‰: docker run --name redis -p 6379:6379 -d redis/redis-stack-server:latest\n",
    "\n",
    "from agent_framework_redis._provider import RedisProvider\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from redisvl.utils.vectorize import AzureOpenAITextVectorizer\n",
    "from redisvl.extensions.cache.embeddings import EmbeddingsCache\n",
    "\n",
    "\n",
    "def search_flights(origin_airport_code: str, destination_airport_code: str, detailed: bool = False) -> str:\n",
    "    \"\"\"í•­ê³µí¸ ê²€ìƒ‰ ë„êµ¬ (ì‹œë®¬ë ˆì´ì…˜)\"\"\"\n",
    "    flights = {\n",
    "        (\"ICN\", \"NRT\"): {\n",
    "            \"airline\": \"Korean Air\",\n",
    "            \"duration\": \"2h 30m\",\n",
    "            \"price\": 250,\n",
    "            \"cabin\": \"Economy\",\n",
    "            \"baggage\": \"2 checked bags\",\n",
    "        },\n",
    "        (\"ICN\", \"LAX\"): {\n",
    "            \"airline\": \"Asiana Airlines\",\n",
    "            \"duration\": \"11h 45m\",\n",
    "            \"price\": 950,\n",
    "            \"cabin\": \"Business\",\n",
    "            \"baggage\": \"3 bags included\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    route = (origin_airport_code.upper(), destination_airport_code.upper())\n",
    "    if route not in flights:\n",
    "        return f\"No flights found from {origin_airport_code} to {destination_airport_code}\"\n",
    "\n",
    "    flight = flights[route]\n",
    "    if not detailed:\n",
    "        return f\"{flight['airline']} operates flights from {origin_airport_code} to {destination_airport_code}.\"\n",
    "\n",
    "    return (\n",
    "        f\"{flight['airline']} operates flights from {origin_airport_code} to {destination_airport_code}. \"\n",
    "        f\"Duration: {flight['duration']}. \"\n",
    "        f\"Price: ${flight['price']}. \"\n",
    "        f\"Cabin: {flight['cabin']}. \"\n",
    "        f\"Baggage policy: {flight['baggage']}.\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"âœ“ Redis í—¬í¼ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c8b70",
   "metadata": {},
   "source": [
    "### 4.2 Redis Context Provider ê¸°ë³¸ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83a40ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Redis Context Provider ê¸°ë³¸ ì˜ˆì œ ===\n",
      "\n",
      "[ì‚¬ìš©ì] Remember that I prefer Korean Air for all my flights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redisvl/redis/connection.py:458: DeprecationWarning: get_async_redis_connection will become async in the next major release.\n",
      "  warn(\n",
      "[2025-11-04 13:45:05 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redisvl/index/index.py:1582 - ERROR] Error while loading data to Redis\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redisvl/index/index.py\", line 1566, in load\n",
      "    return await self._storage.awrite(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redisvl/index/storage.py\", line 503, in awrite\n",
      "    await pipe.execute()\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/asyncio/client.py\", line 1597, in execute\n",
      "    return await conn.retry.call_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/asyncio/retry.py\", line 55, in call_with_retry\n",
      "    raise error\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/asyncio/retry.py\", line 50, in call_with_retry\n",
      "    return await do()\n",
      "           ^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/asyncio/client.py\", line 1509, in _execute_pipeline\n",
      "    await self.parse_response(connection, args[0], **options)\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/asyncio/client.py\", line 1537, in parse_response\n",
      "    result = await super().parse_response(connection, command_name, **options)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/asyncio/client.py\", line 698, in parse_response\n",
      "    response = await connection.read_response()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/asyncio/connection.py\", line 599, in read_response\n",
      "    response = await self._parser.read_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/_parsers/resp2.py\", line 82, in read_response\n",
      "    response = await self._read_response(disable_decoding=disable_decoding)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/_parsers/resp2.py\", line 90, in _read_response\n",
      "    raw = await self._readline()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/_parsers/base.py\", line 285, in _readline\n",
      "    raise ConnectionError(SERVER_CLOSED_CONNECTION_ERROR)\n",
      "redis.exceptions.ConnectionError: Connection closed by server.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Redis Provider ì •ë¦¬ ì™„ë£Œ\n",
      "âš ï¸  ì˜¤ë¥˜ ë°œìƒ: Failed to load data: Connection closed by server.\n",
      "ì˜¤ë¥˜ ìƒì„¸: RedisVLError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redisvl/index/index.py\", line 1566, in load\n",
      "    return await self._storage.awrite(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redisvl/index/storage.py\", line 503, in awrite\n",
      "    await pipe.execute()\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/asyncio/client.py\", line 1597, in execute\n",
      "    return await conn.retry.call_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/asyncio/retry.py\", line 55, in call_with_retry\n",
      "    raise error\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/asyncio/retry.py\", line 50, in call_with_retry\n",
      "    return await do()\n",
      "           ^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/asyncio/client.py\", line 1509, in _execute_pipeline\n",
      "    await self.parse_response(connection, args[0], **options)\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/asyncio/client.py\", line 1537, in parse_response\n",
      "    result = await super().parse_response(connection, command_name, **options)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/asyncio/client.py\", line 698, in parse_response\n",
      "    response = await connection.read_response()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/asyncio/connection.py\", line 599, in read_response\n",
      "    response = await self._parser.read_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/_parsers/resp2.py\", line 82, in read_response\n",
      "    response = await self._read_response(disable_decoding=disable_decoding)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/_parsers/resp2.py\", line 90, in _read_response\n",
      "    raw = await self._readline()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redis/_parsers/base.py\", line 285, in _readline\n",
      "    raise ConnectionError(SERVER_CLOSED_CONNECTION_ERROR)\n",
      "redis.exceptions.ConnectionError: Connection closed by server.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/pr/hngks2mn74d25jycvx6rxl400000gn/T/ipykernel_20941/2087259711.py\", line 88, in <module>\n",
      "    await test_redis_basic()\n",
      "  File \"/var/folders/pr/hngks2mn74d25jycvx6rxl400000gn/T/ipykernel_20941/2087259711.py\", line 63, in test_redis_basic\n",
      "    result = await agent.run(\"Remember that I prefer Korean Air for all my flights\")\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework/_middleware.py\", line 1249, in middleware_enabled_run\n",
      "    return await original_run(self, normalized_messages, thread=thread, **kwargs)  # type: ignore[return-value]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework/observability.py\", line 1117, in trace_run\n",
      "    response = await run_func(self, messages=messages, thread=thread, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework/_agents.py\", line 874, in run\n",
      "    await self._notify_thread_of_new_messages(thread, input_messages, response.messages)\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework/_agents.py\", line 355, in _notify_thread_of_new_messages\n",
      "    await thread.context_provider.invoked(input_messages, response_messages)\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework/_memory.py\", line 268, in invoked\n",
      "    await asyncio.gather(*[\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework_redis/_provider.py\", line 520, in invoked\n",
      "    await self._add(data=messages)\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework_redis/_provider.py\", line 347, in _add\n",
      "    await self.redis_index.load(prepared)\n",
      "  File \"/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/redisvl/index/index.py\", line 1583, in load\n",
      "    raise RedisVLError(f\"Failed to load data: {str(e)}\") from e\n",
      "redisvl.exceptions.RedisVLError: Failed to load data: Connection closed by server.\n"
     ]
    }
   ],
   "source": [
    "async def test_redis_basic():\n",
    "    \"\"\"Redis Context Provider ê¸°ë³¸ ì˜ˆì œ\"\"\"\n",
    "    print(\"=== Redis Context Provider ê¸°ë³¸ ì˜ˆì œ ===\")\n",
    "    \n",
    "    # OpenAI ë²¡í„°ë¼ì´ì € ì„¤ì • (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìš©)\n",
    "    vectorizer = None\n",
    "    if os.getenv(\"AZURE_OPENAI_API_KEY\"):\n",
    "        vectorizer = AzureOpenAITextVectorizer(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            api_config={\n",
    "                \"api_key\": os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "                \"api_version\": \"2024-10-21\",\n",
    "                \"azure_endpoint\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            },\n",
    "            cache=EmbeddingsCache(\n",
    "                name=\"openai_embeddings_cache\",\n",
    "                redis_url=\"redis://localhost:6379\"\n",
    "            ),\n",
    "        )\n",
    "    \n",
    "    # Redis Provider ì„¤ì •\n",
    "    provider_config = {\n",
    "        \"redis_url\": \"redis://localhost:6379\",\n",
    "        \"index_name\": \"workshop_demo\",\n",
    "        \"prefix\": \"workshop_demo\",\n",
    "        \"application_id\": \"workshop_app\",\n",
    "        \"agent_id\": \"demo_agent\",\n",
    "        \"user_id\": \"workshop_user\",\n",
    "        \"overwrite_index\": True,  # ê¸°ì¡´ ì¸ë±ìŠ¤ ë®ì–´ì“°ê¸°\n",
    "    }\n",
    "    \n",
    "    if vectorizer:\n",
    "        provider_config.update({\n",
    "            \"redis_vectorizer\": vectorizer,\n",
    "            \"vector_field_name\": \"vector\",\n",
    "            \"vector_algorithm\": \"hnsw\",\n",
    "            \"vector_distance_metric\": \"cosine\",\n",
    "        })\n",
    "    \n",
    "    provider = RedisProvider(**provider_config)\n",
    "    \n",
    "    client = AzureOpenAIChatClient(\n",
    "        endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        deployment_name=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"),\n",
    "        api_version=\"2024-10-21\",\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # ì—ì´ì „íŠ¸ ìƒì„± (context manager ì‚¬ìš©)\n",
    "        async with client.create_agent(\n",
    "            name=\"TravelAssistant\",\n",
    "            instructions=(\n",
    "                \"You are a helpful travel assistant. \"\n",
    "                \"Personalize replies using provided context. \"\n",
    "                \"Before answering, always check for stored context.\"\n",
    "            ),\n",
    "            tools=[search_flights],\n",
    "            context_providers=provider,\n",
    "        ) as agent:\n",
    "            # ëŒ€í™” ì§„í–‰\n",
    "            print(\"\\n[ì‚¬ìš©ì] Remember that I prefer Korean Air for all my flights\")\n",
    "            result = await agent.run(\"Remember that I prefer Korean Air for all my flights\")\n",
    "            print(f\"[ì—ì´ì „íŠ¸] {result}\\n\")\n",
    "            \n",
    "            print(\"[ì‚¬ìš©ì] Search for flights from ICN to LAX with full details\")\n",
    "            result = await agent.run(\"Search for flights from ICN to LAX with full details\")\n",
    "            print(f\"[ì—ì´ì „íŠ¸] {result}\\n\")\n",
    "            \n",
    "            # ìƒˆ threadì—ì„œ ì„ í˜¸ë„ í™•ì¸\n",
    "            thread = agent.get_new_thread()\n",
    "            print(\"[ì‚¬ìš©ì] What airline do I prefer? (ìƒˆ thread)\")\n",
    "            result = await agent.run(\"What airline do I prefer?\", thread=thread)\n",
    "            print(f\"[ì—ì´ì „íŠ¸] {result}\\n\")\n",
    "    \n",
    "    finally:\n",
    "        # ì •ë¦¬ - providerì˜ close ë©”ì„œë“œ ì‚¬ìš©\n",
    "        try:\n",
    "            if hasattr(provider, 'close'):\n",
    "                await provider.close()\n",
    "            print(\"âœ“ Redis Provider ì •ë¦¬ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ì‹¤í–‰ (Redisì™€ AZURE_OPENAI_API_KEYê°€ í•„ìš”)\n",
    "if os.getenv(\"AZURE_OPENAI_API_KEY\"):\n",
    "    try:\n",
    "        await test_redis_basic()\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        print(f\"ì˜¤ë¥˜ ìƒì„¸: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"âš ï¸  AZURE_OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568a3849",
   "metadata": {},
   "source": [
    "## 5. Thread ê´€ë¦¬ ë° ìŠ¤ì½”í•‘\n",
    "\n",
    "Context ProviderëŠ” ë‹¤ì–‘í•œ ìŠ¤ì½”í•‘ ì „ëµì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "### 5.1 Global Thread Scope\n",
    "\n",
    "ëª¨ë“  operationì—ì„œ ë©”ëª¨ë¦¬ë¥¼ ê³µìœ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ba3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Global Thread Scope ì˜ˆì œ ===\n",
      "Application ID: workshop_app\n",
      "User ID: user123\n",
      "Thread ID: fe128ba9-bf6f-4663-9bc8-da6b4b09ca0a\n",
      "\n",
      "\n",
      "[ì‚¬ìš©ì] Remember that I prefer technical responses with code examples when discussing programming.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework_mem0/_provider.py:124: DeprecationWarning: output_format='v1.0' is deprecated therefore setting it to 'v1.1' by default. Check out the docs for more information: https://docs.mem0.ai/platform/quickstart#4-1-create-memories\n",
      "  await self.mem0_client.add(  # type: ignore[misc]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì—ì´ì „íŠ¸] Got it! For future programming discussions, I'll provide technical responses and include code examples. If you have a specific language or framework preference, let me know.\n",
      "\n",
      "[ì‚¬ìš©ì (ìƒˆ thread)] What do you know about my preferences?\n",
      "[ì—ì´ì „íŠ¸] You prefer technical responses with code examples when discussing programming topics. If you're asking about something related to coding or software development, I will provide detailed explanations along with relevant code samples to help you understand better. Let me know if youâ€™d like to update or add to your preferences!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def test_global_thread_scope():\n",
    "    \"\"\"Global Thread Scope ì˜ˆì œ\"\"\"\n",
    "    print(\"=== Global Thread Scope ì˜ˆì œ ===\")\n",
    "    \n",
    "    if not os.getenv(\"MEM0_API_KEY\"):\n",
    "        print(\"âš ï¸  MEM0_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    application_id = \"workshop_app\"\n",
    "    global_thread_id = str(uuid.uuid4())\n",
    "    user_id = \"user123\"\n",
    "    \n",
    "    print(f\"Application ID: {application_id}\")\n",
    "    print(f\"User ID: {user_id}\")\n",
    "    print(f\"Thread ID: {global_thread_id}\\n\")\n",
    "    \n",
    "    # AsyncMemoryClientë¥¼ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ìƒì„±\n",
    "    mem_client = AsyncMemoryClient(api_key=os.getenv(\"MEM0_API_KEY\"))\n",
    "\n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential).create_agent(\n",
    "            name=\"GlobalMemoryAssistant\",\n",
    "            instructions=\"You are an assistant that remembers user preferences across conversations.\",\n",
    "            context_providers=Mem0Provider(\n",
    "                application_id=application_id,\n",
    "                user_id=user_id,\n",
    "                thread_id=global_thread_id,\n",
    "                mem0_client=mem_client,\n",
    "                scope_to_per_operation_thread_id=False,  # Global scope\n",
    "            ),\n",
    "        ) as agent,\n",
    "    ):\n",
    "        # Global scopeì— ì„ í˜¸ë„ ì €ì¥\n",
    "        query = \"Remember that I prefer technical responses with code examples when discussing programming.\"\n",
    "        print(f\"\\n[ì‚¬ìš©ì] {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"[ì—ì´ì „íŠ¸] {result}\\n\")\n",
    "\n",
    "        # ìƒˆ thread ìƒì„± - global scope ë•ë¶„ì— ë©”ëª¨ë¦¬ ì ‘ê·¼ ê°€ëŠ¥\n",
    "        new_thread = agent.get_new_thread()\n",
    "        query = \"What do you know about my preferences?\"\n",
    "        print(f\"[ì‚¬ìš©ì (ìƒˆ thread)] {query}\")\n",
    "        result = await agent.run(query, thread=new_thread)\n",
    "        print(f\"[ì—ì´ì „íŠ¸] {result}\\n\")\n",
    "\n",
    "await test_global_thread_scope()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8278f2",
   "metadata": {},
   "source": [
    "### 5.2 Per-Operation Thread Scope\n",
    "\n",
    "ê° threadë§ˆë‹¤ ë©”ëª¨ë¦¬ë¥¼ ê²©ë¦¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6947c528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Per-Operation Thread Scope ì˜ˆì œ ===\n",
      "Application ID: workshop_app\n",
      "User ID: user123\n",
      "\n",
      "\n",
      "[ì‚¬ìš©ì] Remember that I'm working on a Python project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework_mem0/_provider.py:124: DeprecationWarning: output_format='v1.0' is deprecated therefore setting it to 'v1.1' by default. Check out the docs for more information: https://docs.mem0.ai/platform/quickstart#4-1-create-memories\n",
      "  await self.mem0_client.add(  # type: ignore[misc]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì—ì´ì „íŠ¸] Got it! Iâ€™ll remember that youâ€™re working on a Python project. If you need help with your code, have questions, or want suggestions, just let me know!\n",
      "\n",
      "[ì‚¬ìš©ì (ê°™ì€ thread)] What am I working on?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-04 13:45:35 - /Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework/_clients.py:609 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì—ì´ì „íŠ¸] You are working on a Python project.\n",
      "\n",
      "[ì‚¬ìš©ì (ë‹¤ë¥¸ thread)] What am I working on?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework_mem0/_provider.py:124: DeprecationWarning: output_format='v1.0' is deprecated therefore setting it to 'v1.1' by default. Check out the docs for more information: https://docs.mem0.ai/platform/quickstart#4-1-create-memories\n",
      "  await self.mem0_client.add(  # type: ignore[misc]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì—ì´ì „íŠ¸] Based on the information I have, you have a meeting every Monday at 9 AM and you like to exercise in the morning. If today is Monday and itâ€™s morning, you would likely be preparing for your meeting or exercising. If you share more context or specify the day/time, I can be more precise!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def test_per_operation_thread_scope():\n",
    "    \"\"\"Per-Operation Thread Scope ì˜ˆì œ\"\"\"\n",
    "    print(\"=== Per-Operation Thread Scope ì˜ˆì œ ===\")\n",
    "    \n",
    "    if not os.getenv(\"MEM0_API_KEY\"):\n",
    "        print(\"âš ï¸  MEM0_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    application_id = \"workshop_app\"\n",
    "    user_id = \"user123\"\n",
    "    \n",
    "    print(f\"Application ID: {application_id}\")\n",
    "    print(f\"User ID: {user_id}\\n\")\n",
    "    \n",
    "    # AsyncMemoryClientë¥¼ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ìƒì„±\n",
    "    mem_client = AsyncMemoryClient(api_key=os.getenv(\"MEM0_API_KEY\"))\n",
    "\n",
    "    async with AzureCliCredential() as credential:\n",
    "        # ì²« ë²ˆì§¸ thread - ì •ë³´ ì €ì¥\n",
    "        async with AzureAIAgentClient(async_credential=credential).create_agent(\n",
    "            name=\"ScopedMemoryAssistant\",\n",
    "            instructions=\"You are an assistant with thread-scoped memory.\",\n",
    "            context_providers=Mem0Provider(\n",
    "                application_id=application_id,\n",
    "                user_id=user_id,\n",
    "                mem0_client=mem_client,\n",
    "                scope_to_per_operation_thread_id=True,  # Per-operation scope\n",
    "            ),\n",
    "        ) as agent:\n",
    "            dedicated_thread = agent.get_new_thread()\n",
    "\n",
    "            # ì´ threadì—ë§Œ ì •ë³´ ì €ì¥\n",
    "            query = \"Remember that I'm working on a Python project\"\n",
    "            print(f\"\\n[ì‚¬ìš©ì] {query}\")\n",
    "            result = await agent.run(query, thread=dedicated_thread)\n",
    "            print(f\"[ì—ì´ì „íŠ¸] {result}\\n\")\n",
    "\n",
    "            # ê°™ì€ threadì—ì„œ ì •ë³´ ì¡°íšŒ\n",
    "            query = \"What am I working on?\"\n",
    "            print(f\"[ì‚¬ìš©ì (ê°™ì€ thread)] {query}\")\n",
    "            result = await agent.run(query, thread=dedicated_thread)\n",
    "            print(f\"[ì—ì´ì „íŠ¸] {result}\\n\")\n",
    "        \n",
    "        # ë‘ ë²ˆì§¸ thread - ìƒˆ agent ì¸ìŠ¤í„´ìŠ¤ í•„ìš” (per-operation scope)\n",
    "        async with AzureAIAgentClient(async_credential=credential).create_agent(\n",
    "            name=\"ScopedMemoryAssistant\",\n",
    "            instructions=\"You are an assistant with thread-scoped memory.\",\n",
    "            context_providers=Mem0Provider(\n",
    "                application_id=application_id,\n",
    "                user_id=user_id,\n",
    "                mem0_client=mem_client,\n",
    "                scope_to_per_operation_thread_id=True,  # Per-operation scope\n",
    "            ),\n",
    "        ) as agent2:\n",
    "            another_thread = agent2.get_new_thread()\n",
    "            query = \"What am I working on?\"\n",
    "            print(f\"[ì‚¬ìš©ì (ë‹¤ë¥¸ thread)] {query}\")\n",
    "            result = await agent2.run(query, thread=another_thread)\n",
    "            print(f\"[ì—ì´ì „íŠ¸] {result}\\n\")\n",
    "\n",
    "await test_per_operation_thread_scope()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7debccac",
   "metadata": {},
   "source": [
    "### 5.3 Multiple Agents with Different Configurations\n",
    "\n",
    "ì—¬ëŸ¬ ì—ì´ì „íŠ¸ê°€ ê°ê° ë‹¤ë¥¸ ë©”ëª¨ë¦¬ ì„¤ì •ì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ê²©ë¦¬ ì˜ˆì œ ===\n",
      "Application ID: workshop_app\n",
      "Personal Agent ID: agent_personal\n",
      "Work Agent ID: agent_work\n",
      "User ID: user123\n",
      "\n",
      "\n",
      "[ì‚¬ìš©ì -> Personal Agent] Remember I like to exercise in the morning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework_mem0/_provider.py:124: DeprecationWarning: output_format='v1.0' is deprecated therefore setting it to 'v1.1' by default. Check out the docs for more information: https://docs.mem0.ai/platform/quickstart#4-1-create-memories\n",
      "  await self.mem0_client.add(  # type: ignore[misc]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Personal Agent] Got it! You like to exercise in the morning. Would you like me to help you schedule your workouts, set reminders, or track your progress?\n",
      "\n",
      "[ì‚¬ìš©ì -> Work Agent] Remember I have a meeting every Monday at 9 AM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/works/ai/maf-workshop/.venv/lib/python3.12/site-packages/agent_framework_mem0/_provider.py:124: DeprecationWarning: output_format='v1.0' is deprecated therefore setting it to 'v1.1' by default. Check out the docs for more information: https://docs.mem0.ai/platform/quickstart#4-1-create-memories\n",
      "  await self.mem0_client.add(  # type: ignore[misc]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Work Agent] Got it! Iâ€™ll remember that you have a meeting every Monday at 9 AM. If you need reminders, assistance with agenda preparation, or meeting notes, just let me know!\n",
      "\n",
      "[ì‚¬ìš©ì -> Personal Agent] What do you know about my schedule?\n",
      "[Personal Agent] I donâ€™t have access to your personal schedule unless youâ€™ve shared the details with me in this conversation. If youâ€™d like help managing or organizing your schedule, just let me know the events, tasks, or appointments you have! I can also suggest ways to keep track of your plans or help you use a calendar app if needed. How can I assist you with your schedule today?\n",
      "\n",
      "[ì‚¬ìš©ì -> Work Agent] What do you know about my preferences?\n",
      "[Work Agent] I donâ€™t have access to your personal data or history unless youâ€™ve shared it with me during this conversation or in previous interactions. I donâ€™t retain information between sessions for privacy reasons. If you tell me more about your preferences (work style, scheduling, professional goals, etc.), I can tailor my responses and assistance accordingly! Please let me know your preferences so I can better help you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def test_multiple_agents():\n",
    "    \"\"\"ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ê²©ë¦¬ ì˜ˆì œ\"\"\"\n",
    "    print(\"=== ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ê²©ë¦¬ ì˜ˆì œ ===\")\n",
    "    \n",
    "    if not os.getenv(\"MEM0_API_KEY\"):\n",
    "        print(\"âš ï¸  MEM0_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    application_id = \"workshop_app\"\n",
    "    agent_id_1 = \"agent_personal\"\n",
    "    agent_id_2 = \"agent_work\"\n",
    "    user_id = \"user123\"\n",
    "    \n",
    "    print(f\"Application ID: {application_id}\")\n",
    "    print(f\"Personal Agent ID: {agent_id_1}\")\n",
    "    print(f\"Work Agent ID: {agent_id_2}\")\n",
    "    print(f\"User ID: {user_id}\\n\")\n",
    "    \n",
    "    # AsyncMemoryClientë¥¼ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ìƒì„±\n",
    "    mem_client = AsyncMemoryClient(api_key=os.getenv(\"MEM0_API_KEY\"))\n",
    "\n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential).create_agent(\n",
    "            name=\"PersonalAssistant\",\n",
    "            instructions=\"You are a personal assistant that helps with personal tasks.\",\n",
    "            context_providers=Mem0Provider(\n",
    "                application_id=application_id,\n",
    "                agent_id=agent_id_1,\n",
    "                user_id=user_id,\n",
    "                mem0_client=mem_client\n",
    "            ),\n",
    "        ) as personal_agent,\n",
    "        AzureAIAgentClient(async_credential=credential).create_agent(\n",
    "            name=\"WorkAssistant\",\n",
    "            instructions=\"You are a work assistant that helps with professional tasks.\",\n",
    "            context_providers=Mem0Provider(\n",
    "                application_id=application_id,\n",
    "                agent_id=agent_id_2,\n",
    "                user_id=user_id,\n",
    "                mem0_client=mem_client\n",
    "            ),\n",
    "        ) as work_agent,\n",
    "    ):\n",
    "        # Personal agentì— ì •ë³´ ì €ì¥\n",
    "        print(\"\\n[ì‚¬ìš©ì -> Personal Agent] Remember I like to exercise in the morning\")\n",
    "        result = await personal_agent.run(\"Remember I like to exercise in the morning\")\n",
    "        print(f\"[Personal Agent] {result}\\n\")\n",
    "\n",
    "        # Work agentì— ì •ë³´ ì €ì¥\n",
    "        print(\"[ì‚¬ìš©ì -> Work Agent] Remember I have a meeting every Monday at 9 AM\")\n",
    "        result = await work_agent.run(\"Remember I have a meeting every Monday at 9 AM\")\n",
    "        print(f\"[Work Agent] {result}\\n\")\n",
    "\n",
    "        # Personal agentëŠ” ê°œì¸ ì •ë³´ë§Œ ì•Œê³  ìˆìŒ\n",
    "        print(\"[ì‚¬ìš©ì -> Personal Agent] What do you know about my schedule?\")\n",
    "        result = await personal_agent.run(\"What do you know about my schedule?\")\n",
    "        print(f\"[Personal Agent] {result}\\n\")\n",
    "\n",
    "        # Work agentëŠ” ì—…ë¬´ ì •ë³´ë§Œ ì•Œê³  ìˆìŒ\n",
    "        print(\"[ì‚¬ìš©ì -> Work Agent] What do you know about my preferences?\")\n",
    "        result = await work_agent.run(\"What do you know about my preferences?\")\n",
    "        print(f\"[Work Agent] {result}\\n\")\n",
    "\n",
    "await test_multiple_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d60417",
   "metadata": {},
   "source": [
    "## ìš”ì•½\n",
    "\n",
    "ì´ ì›Œí¬ìƒµì—ì„œëŠ” ë‹¤ìŒ ë‚´ìš©ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. **ì»¤ìŠ¤í…€ Context Provider**: `ContextProvider` ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•˜ì—¬ ìì²´ ë©”ëª¨ë¦¬ ë¡œì§ ìƒì„±\n",
    "2. **Mem0 Context Provider**: Mem0 Platform ë˜ëŠ” OSSë¥¼ ì‚¬ìš©í•œ ìê°€ ê°œì„  ë©”ëª¨ë¦¬\n",
    "3. **Redis Context Provider**: Redisë¥¼ ì‚¬ìš©í•œ ì˜êµ¬ì ì´ê³  ê²€ìƒ‰ ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬\n",
    "4. **Thread ìŠ¤ì½”í•‘**:\n",
    "   - Global scope: ëª¨ë“  operationì—ì„œ ë©”ëª¨ë¦¬ ê³µìœ \n",
    "   - Per-operation scope: threadë³„ ë©”ëª¨ë¦¬ ê²©ë¦¬\n",
    "   - Multiple agents: agentë³„ ë©”ëª¨ë¦¬ ê²©ë¦¬\n",
    "\n",
    "### ì£¼ìš” ê°œë…\n",
    "\n",
    "- **`invoking()`**: ì—ì´ì „íŠ¸ í˜¸ì¶œ ì „ì— ì»¨í…ìŠ¤íŠ¸ ì œê³µ\n",
    "- **`invoked()`**: ì—ì´ì „íŠ¸ í˜¸ì¶œ í›„ì— ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸\n",
    "- **Scoping**: `application_id`, `agent_id`, `user_id`, `thread_id`ë¥¼ í†µí•œ ë©”ëª¨ë¦¬ ê²©ë¦¬\n",
    "- **Persistence**: ëŒ€í™” ì„¸ì…˜ ê°„ ì¥ê¸° ë©”ëª¨ë¦¬ ìœ ì§€\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "1. í”„ë¡œë•ì…˜ í™˜ê²½ì— ë§ëŠ” Context Provider ì„ íƒ\n",
    "2. ì ì ˆí•œ ìŠ¤ì½”í•‘ ì „ëµ ê²°ì •\n",
    "3. ë²¡í„° ê²€ìƒ‰ í™œìš© (Redis, Mem0)\n",
    "4. ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ê´€ë¦¬ ì „ëµ ìˆ˜ë¦½"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maf-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
